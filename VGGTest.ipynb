{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import ImageData\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG\"\n",
    "model_image_size = 224\n",
    "# vit = models.vit_l_16(models.ViT_L_16_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(torch.nn.Module):\n",
    "    def __init__(self, numClasses):\n",
    "        super(VGG, self).__init__()\n",
    "        vgg = vgg19(weights = \"DEFAULT\")\n",
    "        self.featureExtractor = vgg.features\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.class1, _, _, self.class2, _, _, _  = list(vgg.classifier.children())\n",
    "        self.class3 = torch.nn.Linear(in_features = 4096, out_features = numClasses)\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            self.class1,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.class2,\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            self.class3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #do something \n",
    "        x = self.featureExtractor(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG(4).to(device)\n",
    "# print(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.RandomResizedCrop(size=(model_image_size, model_image_size), antialias=True), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainDataLoader, validDataLoader, testDataLoader = ImageData.getImagesDataloaders(\"../ArtiFact/\", transforms = transform, batchSize=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trainDataLoader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdxs, _ = train_test_split(range(len(dataset.imagePaths)), train_size=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValIdxs = trainIdxs[100:]\n",
    "trainIdxs = trainIdxs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainIdxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSub = Subset(dataset, trainIdxs)\n",
    "valSub = Subset(dataset, ValIdxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSubDataloader = DataLoader(trainSub, batch_size=32, shuffle=True)\n",
    "valSubDataloader = DataLoader(valSub, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_data(model, dataloader, dirty: bool = False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        \n",
    "        num_correct = 0.0\n",
    "        num_samples = 0.0\n",
    "        for data in tqdm(dataloader, desc=\"Eval: \"):\n",
    "            image, label = data\n",
    "            label = label.to(device)\n",
    "            image = image.to(device)\n",
    "            outputs = model(image)\n",
    "            if dirty:\n",
    "                label = torch.where(label > 1, torch.tensor(1, dtype = torch.int32).to(device), label)\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, label)\n",
    "            total_loss += loss.item()\n",
    "            argMax = torch.argmax(outputs, 1)\n",
    "            for i in range(len(label)):\n",
    "                if label[i] == argMax[i]:\n",
    "                    num_correct += 1\n",
    "\n",
    "                num_samples += 1\n",
    "                    \n",
    "                \n",
    "                \n",
    "    return total_loss / len(dataloader), num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/117213 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:23:51<00:00,  6.03it/s]  \n",
      "Eval: 100%|██████████| 6170/6170 [14:39<00:00,  7.01it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [13:48<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.8625, Valid Loss: 1.0549165871869803, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:24:11<00:00,  6.03it/s]  \n",
      "Eval: 100%|██████████| 6170/6170 [14:16<00:00,  7.21it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [14:00<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.9617, Valid Loss: 1.0550024736739054, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:51:04<00:00,  5.56it/s]  \n",
      "Eval: 100%|██████████| 6170/6170 [25:59<00:00,  3.96it/s] \n",
      "Eval: 100%|██████████| 6170/6170 [25:25<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 1.3406, Valid Loss: 1.0547520756624893, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [6:26:57<00:00,  5.05it/s]  \n",
      "Eval: 100%|██████████| 6170/6170 [10:59<00:00,  9.35it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [10:38<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.8423, Valid Loss: 1.0548256373192928, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:18:18<00:00,  6.14it/s] \n",
      "Eval: 100%|██████████| 6170/6170 [10:45<00:00,  9.56it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [09:47<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.9887, Valid Loss: 1.0551087519434708, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:18:03<00:00,  6.14it/s] \n",
      "Eval: 100%|██████████| 6170/6170 [10:47<00:00,  9.52it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [09:44<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 1.3367, Valid Loss: 1.0549204005414508, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:23:53<00:00,  6.03it/s]  \n",
      "Eval: 100%|██████████| 6170/6170 [10:51<00:00,  9.47it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [10:50<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 1.0758, Valid Loss: 1.054734987590456, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:26:31<00:00,  5.98it/s] \n",
      "Eval: 100%|██████████| 6170/6170 [08:17<00:00, 12.40it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [08:14<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.9442, Valid Loss: 1.054804602849812, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 117213/117213 [5:25:51<00:00,  6.00it/s] \n",
      "Eval: 100%|██████████| 6170/6170 [08:13<00:00, 12.51it/s]\n",
      "Eval: 100%|██████████| 6170/6170 [08:10<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 1.0932, Valid Loss: 1.0549815429957219, Valid ACC: 0.4855681069854617, Dirty Valid ACC: 0.6085811255762119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|███████▎  | 85358/117213 [3:56:44<1:30:56,  5.84it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "count = 0\n",
    "valid_loss_array = np.zeros(num_epochs)\n",
    "valid_acc_array = np.zeros(num_epochs)\n",
    "valid_acc_dirty_array = np.zeros(num_epochs)\n",
    "\n",
    "train_loss_array = np.zeros(num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    batch_count = 0\n",
    "    for data in tqdm(trainDataLoader, desc=\"Training: \"):\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        label = label.to(device)\n",
    "        image = image.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        # print(loss)\n",
    "            \n",
    "        \n",
    "    valid_loss, valid_acc = evaluate_on_data(model, validDataLoader)\n",
    "    _, valid_acc_dirty = evaluate_on_data(model, validDataLoader, dirty=True)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}, Valid Loss: {valid_loss}, Valid ACC: {valid_acc}, Dirty Valid ACC: {valid_acc_dirty}')\n",
    "    valid_loss_array[epoch] = valid_loss\n",
    "    train_loss_array[epoch] = loss.item()\n",
    "    valid_acc_array[epoch] = valid_acc\n",
    "    valid_acc_dirty_array[epoch] = valid_acc_dirty\n",
    "\n",
    "#9:53:40\n",
    "#9:55:28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_name}_valid_loss.npy\", 'wb') as f:\n",
    "    np.save(f, valid_loss_array)\n",
    "    \n",
    "with open(f\"{model_name}_valid_acc.npy\", 'wb') as f:\n",
    "    np.save(f, valid_acc_array)\n",
    "\n",
    "with open(f\"{model_name}_valid_dirty_acc.npy\", 'wb') as f:\n",
    "    np.save(f, valid_acc_dirty_array)\n",
    "    \n",
    "with open(f\"{model_name}_train.npy\", 'wb') as f:\n",
    "    np.save(f, train_loss_array)\n",
    "\n",
    "torch.save(model.state_dict(), f\"./results/{model_name}Params.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8907f5995ab74a6cd5df9da2d2bcd12f57f5b23c9c38358337eeb837f01ad676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
